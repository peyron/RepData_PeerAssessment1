library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "ae09e1c32053a515a4c7",
secret = "ce7daff0c4a7fe4d483052f6fb7a5875e3e75919")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
## https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html:
headers(req)
str(content(req, "parsed"))
str(content(req, "text"))
str(content(req))
content(req, "raw")
data <- as.data.frame(matrix(unlist(content(req)), ncol = 69))
View(data)
install.packages("josnlite")
install.packages("jsonlite")
install.packages("jsonlite")
install.packages("jsonlite")
install.packages("jsonlite")
require(jsonlite)
require(swril)
require(swirl)
swirl()
read.csv("path2csv", stringsAsFactors = FALSE)
read.csv("path2csv.csv", stringsAsFactors = FALSE)
mydf  <- read.csv("path2csv.csv", stringsAsFactors = FALSE)
mydf  <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("splyr")
packageVersion("dplyr")
cran  <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, - time
)
select(cran, -X:size)
select(cran, -5:20)
-5:20
-(5:20)
select(cran, -(X:size)
)
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1",
| country == "US")
filter(cran, r_version == "3.1.1",   | country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US"| country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10)
)
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version)
)
cran2  <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package,
| ip_id)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3  <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dlyr)
library(dplyr)
cran  <- tbl_df(by_package)
cran  <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package  <-  group_by(cran, package)
by_package
summarize(by_package, size, mean)
summarize(by_package, mean)
summarize(by_package, mean(size))
options(editor = "internal")
swirl()
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > quantile(pack_sum$count, probs = 0.99))
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
arrange(top_counts, count)
arrange(top_counts, desc(count)
)
top_counts_sorted  <- arrange(top_counts, desc(count)
)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted  <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
View(cran)
submit()
submit()
submit()
submit()
submit()
require(swirl)
swirl()
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment  <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
now("America/New_York")
now("America/New_York")
nyc  <- now("America/New_York")
nyc
depart  <-  nyc + days(2)
depart
depart  <-  update(depart, hours = 17, minutes = 34)
depart
arrive  <- depart + hours(15) + minutes(50)
?with_tz
arrie  <- with_tz(arrive, "Asia/Hong_Kong")
arrive  <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time  <- mdy("June 17, 2008", tz = "Singapore")
last_time
last_time
?interval
how_long  <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
?functionplotR
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend", "devtools", "digest", "dplyr", "ggthemes", "ggvis", "htmlwidgets", "httr", "knitr", "lazyeval", "maps", "mime", "multcomp", "openssl", "partykit", "plyr", "psych", "Rcpp", "readr", "rmarkdown", "rstudioapi", "seriation", "swirl", "tidyr", "withr"))
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend",
)
)
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend"))
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend"))
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend"))
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend"))
install.packages(c("corrgram", "crayon", "curl", "DBI", "dendextend"))
install.packages(c("devtools", "digest", "dplyr", "ggthemes", "ggvis", "htmlwidgets", "httr", "knitr", "lazyeval", "maps", "mime", "multcomp", "openssl", "partykit", "plyr", "psych", "Rcpp", "readr", "rmarkdown", "rstudioapi", "seriation", "swirl", "tidyr", "withr"))
install.packages(c("devtools", "digest", "dplyr", "ggthemes",
install.packages("shinyjs")
data <- read.csv("activity.csv")
setwd("C:/Users/kristoffer.peyron/Dropbox/Coursera/Data Science Specialization/5. Reproducible Research/week 2/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
stepsByDate <- data %>% group_by(date) %>%
summarise(steps = sum(steps))
require(dplyr)
stepsByDate <- data %>% group_by(date) %>%
summarise(steps = sum(steps))
avgStepsByInterval <- data %>% group_by(interval) %>% summarise(avgSteps = mean(steps, na.rm = TRUE))
tapply(data$steps, data$steps, mean)
tapply(data$steps, data$interval, mean)
tapply(data$steps, data$interval, mean)
dataImput <- data
length(dataInput)
length(dataInput)
dataInput <- data
length(dataInput)
nrow(dataInput)
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i]){
dataInput$steps[i] <- avgStepsByInterval[,dataInput$interval == avgStepsByInterval$interval]
}
}
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i]){
dataInput$steps[i] <- avgStepsByInterval$avgSteps[,dataInput$interval == avgStepsByInterval$interval]
}
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i]){
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i])){
dataInput$steps[i] <- avgStepsByInterval$avgSteps[,dataInput$interval == avgStepsByInterval$interval]
}
}
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i])){
dataInput$steps[i] <- avgStepsByInterval$avgSteps[dataInput$interval == avgStepsByInterval$interval,]
}
}
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i])){
dataInput$steps[i] <- avgStepsByInterval$avgSteps[dataInput$interval == avgStepsByInterval$interval]
}
}
warnings()
str(dataInput)
str(data)
View(dataInput)
View(data)
dataInput <- data
for(i in 1:nrow(dataInput)){
if(is.na(dataInput$steps[i])){
dataInput$steps[i] <- avgStepsByInterval$avgSteps[dataInput$interval[i] == avgStepsByInterval$interval]
}
}
View(dataInput)
View(avgStepsByInterval)
